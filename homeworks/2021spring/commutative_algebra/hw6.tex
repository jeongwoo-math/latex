\documentclass{scrartcl}
\usepackage{../../styles/style}

%\darkmode
% https://jangsookim.github.io/lectures/vscode/vscode_lecture0.html

\title{
    Introduction to Commutative Algebra \\ \Large
    --- Solution of Homework 6 ---
    }
\author{20190262 Jeongwoo Park}
\date{}
\begin{document}
    \maketitle

    \section{Solutions}

    \begin{proof}[Solution of Problem 1]
        \begin{enumerate}
            \item We need a lemma.
            
            \begin{Lemma}[rational root test]\label{rational root test}
                Let $R$ be a UFD. For any polynomial $f(x) = \sum_{i \ge 0} a_i x^i$ of degree $n$, if $f\left( \frac{a}{b} \right) = 0$ for some elements $a,b \in R$ such that $\gcd(a,b) = 1$, relations $a \mid a_0, b \mid a_n$ hold.
            \end{Lemma}

            \begin{proof}[Proof of Lemma~\ref{rational root test}]
                By the assumption, we have an equality
                $$ a_n \cdot \left( \frac{a}{b} \right)^n + a_{n-1} \cdot \left( \frac{a}{b} \right) + \cdots + a_0 = 0 $$
                If we multiply $b^n$ at the equation, then we ca know that
                $$ a_n a^n + a_{n-1} a^{n-1} b + \cdots + a_0 b^n = 0 $$
                Thus, we can conclude that
                $$ 0 \equiv a_n a^n + a_{n-1} a^{n-1} b + \cdots + a_0 b^n \equiv a_0 b^n \, (\operatorname{mod}\, a) $$
                and
                $$ 0 \equiv a_n a^n + a_{n-1} a^{n-1} b + \cdots + a_0 b^n \equiv a_n a^n \, (\operatorname{mod}\, b) $$
                Because $\gcd(a,b) = 1$, one can deduce that $a \mid a_0$ and $b \mid a_n$. This completes the proof.
            \end{proof}

            By the lemma above, one can know that an element $\frac{a}{b} \in \Frac A$ is a zero of a monic polynomial over $A$ only if the denominator is a unit in $A$, i.e., $\frac{a}{b}$ is integral only when it is an element of $A$. Hence, $A$ is integrally closed domain, or equivalently, it is normal. This completes the proof.

            \item Consider a ring homomorphism $\varphi : k[x,y] \to k[t], x \mapsto t, y \mapsto t^2$. Then, this map is surjective, and the kernel of this map contains the ideal $\left\langle y-x^2 \right\rangle$. Let's pick an element $f(x,y) \in \ker \varphi$. By considering a sort of division, there are polynomials $q(x,y) \in k[x,y]$ and $r(x) \in k[x]$ such that $f(x,y) = \left( y-x^2 \right) \cdot q(x,y) + r(x)$. Hence, we have an equality $ 0 = \varphi(f(x,y)) = r(t)$, or equivalently, $r(x) = 0$. This means that $\ker \varphi = \left\langle y-x^2 \right\rangle$, and by the first isomorphism theorem, one can conclude that
            $$ \frac{k[x,y]}{\left\langle y-x^2 \right\rangle} \cong k[t] $$
            Since $k[t]$ is an ED, so it is a UFD. In particular, this ring is normal, so the quotient ring $\frac{k[x,y]}{\left\langle y-x^2 \right\rangle}$ is normal. This completes the proof.

            \item Note that $x \notin \left\langle y^2-x^3 \right\rangle$, and an element $\frac{\overline y}{\overline x}$ is a solution of a monic polynomial $t^3- \overline y \in \left( \frac{k[x,y]}{\left\langle y^2-x^3 \right\rangle} \right)[t]$, since
            $$ \left( \frac{\overline y}{\overline x} \right)^3 - \overline y = \frac{\overline y^3}{\overline x^3} - \overline y = \frac{\overline y^3}{\overline y^2} - \overline y = 0 $$
            holds. However, $\frac{\overline y}{\overline x}$ is not an element of $\frac{k[x,y]}{\left\langle y^2 - x^3 \right\rangle}$, because if it was, then there must be an element $f(x,y) \in k[x,y]$ such that $xf(x,y)-y \in \left\langle y^2 - x^3 \right\rangle$. But if we evaluate $x=0$, then one can deduce a relation $y \in \left\langle y^2 \right\rangle$, and this makes a contradiction. Hence, the ring $\frac{k[x,y]}{\left\langle y^2 - x^3 \right\rangle}$ is not integrally closed, and this is what we want to show.
        \end{enumerate}
    \end{proof}

    \begin{proof}[Solution of Problem 2]
        It is enough to show that $f^*(V(I)) = V(f^{-1}(I))$. Since $f$ is integral, so the induced map $\overline f : A/f^{-1}(I) \to B/I$ is also integral. Hence, the induced map $\overline f^* : \Spec (B/I) \to \Spec \left(A/f^{-1}(I)\right)$ is surjective. However, the diagram
        $$
        \begin{tikzcd}%[column sep = ]
            \Spec(B/I) \arrow[r, "\overline f^*"] \arrow[d, "\cong"'] & \Spec \left(A/f^{-1}(I)\right) \arrow[d, "\cong"] \\
            V(I) \arrow[r, "f^*|_{V(I)}"] & V(f^{-1}(I))
        \end{tikzcd}
        $$
        commutes where the vertical maps are homeomorphisms induced by the correspondence theorem, since we have a diagram
        $$
        \begin{tikzcd}%[column sep = ]
            P/I \arrow[r, mapsto] \arrow[d, mapsto] & f^{-1}(P)/f^{-1}(I) \arrow[d, mapsto]\\
            P \arrow[r, mapsto] & f^{-1}(P)
        \end{tikzcd}
        $$
        at the level of elements. Therefore, the map $f|_{V(I)}$ is surjective, and this completes the proof.
    \end{proof}

    \begin{proof}[Solution of Problem 3]
        Since the tensor product $B_2 \otimes_{A} C$ is generated by decomposable tensors, it is enough to show that $b \otimes c$ is integral over the image of $f \otimes \id$, for all $b \in B_2$ and $c \in C$. Because the map $f$ is integral, there are elements $b_i \in B_1$ such that $b^n + f(b_{n-1}) b^n + \cdots + f(b_0) = 0$. By taking the map $- \otimes c^n$, we have the identity
        \begin{align*}
            0 &= b^n \otimes c^n + f(b_{n-1}) \cdot (b^{n-1} \otimes c^n) + \cdots + f(b_0) \cdot (1 \otimes c^n)\\
            &= (b \otimes c)^n + (f(b_{n-1}) \otimes c) \cdot (b \otimes c)^{n-1} + \cdot + (f(b_0) \otimes c^n)
        \end{align*}
        Thus, $b \otimes c$ is integral over the image of $f \otimes \id$, because $f(b_i) \otimes c^{n-i} = (f \otimes \id) ( b_i, c^{n-i})$ hold for all $0 \le i \le n-1$. This concludes the result.
    \end{proof}

    \begin{proof}[Solution of Problem 4]
        Since $x^{-1}$ is integral over $A$, there are elements $a_i \in A$ such that
        $$ \left( x^{-1} \right)^n + a_{n-1} \left( x^{-1} \right)^{n-1} +  \cdots + a_0 = 0 $$
        If we multiply $x^n$ at that equation, then one can deduce that
        $$ 1 + a_{n-1} x + \cdots + a_0 x^n =0 $$
        or equivalently,
        $$ x \cdot \left(-a_{n-1} - a_{n-2} x - \cdots - a_0 x^{n-1}\right) = 1 $$
        Because $x \in A$, we can conclude that $-a_{n-1} - a_{n-2} x - \cdots - a_0 x^{n-1} \in A$. Hence, $x$ is a unit element of $A$.
    \end{proof}

    \begin{proof}[Solution of Problem 5]
        \begin{enumerate}
            \item From the next lemma, we can immediately conclude the result.
            
            \begin{Lemma}\label{induced map on unit group}
                Let $\phi : A \to B$ a ring map. Then the restriction $\phi^\times := \phi|_{A^\times}$ forms a group homomorphism from $A^\times$ to $B^\times$.
            \end{Lemma}

            \begin{proof}[Proof of Lemma~\ref{induced map on unit group}]
                Let $u$ be a unit element of $A$, then it is clear that the multiplicative inverse of $\phi(a)$ is $\phi(a^{-1})$, i.e., $\phi(a) \in B^\times$ holds. Hence, $\phi^\times$ is well-define as a function. Moreover, it forms a group homomorphism since this commute with the multiplication. This completes the proof.
            \end{proof}

            \item Let consider a map $\phi : \mathbb{Z} \to \mathbb{Z}/5 \mathbb{Z}$, then the indeuced group homomorphism can't be surjective since $\left \lvert \mathbb{Z}^\times \right \rvert = 2 < \left \lvert \left( \mathbb{Z}/5 \mathbb{Z} \right)^\times  \right \rvert = 4$.
            
            \item We need a lemma.
            
            \begin{Lemma}\label{local epimorphism induces an epimorphism}
                Let $\phi : A \to B$ be a local epimorphism where $(A, \mathfrak{m})$ and $(B, \mathfrak{n})$ are local rings. Then, the induced map $\phi^\times : A^\times \to B^\times$ is surjective.
            \end{Lemma}

            \begin{proof}[Proof of Lemma~\ref{local epimorphism induces an epimorphism}]
                Note that $A^\times = A \setminus \mathfrak{m}$ and $B^\times = B \setminus \mathfrak{n}$. It is enough to show that $\phi\left( A \setminus \mathfrak{m} \right) \supseteq B \setminus \mathfrak{n}$. We have a relation
                $$ \phi(A \setminus \mathfrak{m}) \supseteq \phi(A) \setminus \phi(\mathfrak{m}) \supseteq B \setminus \mathfrak{n} $$
                because $\phi$ is local, and this completes the proof.
            \end{proof}

            Note that the map $\phi : A \to A/I$ is a surjective local homomorphism when $A$ is local, by the correspondence theorem. By the lemma, the induced group homomorphism $\phi^\times : A ^\times \to (A/I) ^\times$ is surjective. This completes the proof.
        \end{enumerate}
    \end{proof}

    \begin{proof}[Solution of Problem 6]
        Let's consider a surjective $k$-algebra map $\varphi : k[x_i]_{1 \le i \le r} \to k[a_i]_{1 \le i \le r}$. Then, the kernel of this map is zero, since if $f(x_i)_i \in \ker \varphi$, then $f(a_i)_i = 0$ holds. However, this implies that $f(x_i)_i = 0$, because $a_i$'s are algebraically independent. Now, by the first isomorphism theorem, one can conclude that $k[x_i]_i \cong k[a_i]_i$, and this is what we want to show.
    \end{proof}

    \begin{proof}[Solution of Problem 7]
        Since $A$ is finite-type, there are finitely many elements $a_i \in A$ such that $A = k[a_i]_{1 \le i \le n}$. I'll moreover show that $r \le n$. Also, I'll use the mathematical induction on $n$.

        When $n = 1$, the result is clear, since if $a_1$ is algebraic, then $A/k$ is integral, and if $a_1$ is transcendental, then we can take $y_1 = a_1$.

        Now, let's assume that the proposition holds for all natural numbers less than $n \ge 2$. Let $A' = k[a_i]_{1 \le i \le n-1}$, then there are algebraically independent elements $y_j$ such that $A'/k[y_j]_{1 \le j \le r}$ is integral. If $a_n$ is integral over $k[y_j]_j$, then the extension $A/k[y_j]_j$ must be integral, and we are done. So, let's assume that $a_n$ is not integral over $k[y_j]_j$. If the set $\left\{ a_n y_j \right\}_j$ is algebraically independent, then we can take $y_{r+1} = a_n$ and we are done, because $A'[a_n]/k[a_n, y_j]_j$ is clearly integral. If not, there is a non-zero polynomial $f(x_0, x_j)_j = \sum_\alpha c_\alpha x_\bullet^\alpha$ such that $f(a_n, y_j)_j = 0$. Let $n$ be the degree of $f(x_\bullet)$, and let $f_n(x_\bullet)$ be the degree $n$ homogeneous factor of $f(x_\bullet)$, i.e., sum of all degree $n$ terms of $f(x_\bullet)$. We consider a modified polynomial $g(x_\bullet) := f(x_0, x_j + \lambda_j x_j)_j$, then this is a polynomial of degree $n$. The coefficient of $x_0^n$ in $g(x_\bullet)$ is $\sum_{\alpha \,;\, |\alpha|_1 = n} \left( c_\alpha \cdot \prod_{i=1}^r \lambda_i^{\alpha_i} \right)$. We need a lemma.
        
        \begin{Lemma}\label{evaluation lemma}
            Let $k$ be an infinite field, and $f(x_i)_i$ is a $n$-variable polynomial over $k$. If $f(a_i)_i = 0$ for all $a_i \in k$, then $f(x_i)_i = 0$.
        \end{Lemma}

        \begin{proof}[Proof of Lemma~\ref{evaluation lemma}]
            I'll use the mathematical induction on $n$. If $n=1$, then it is clear since every non-zero polynomial has only finitely many zeros, but $k$ is infinite. Now, suppose that the proposition is true for every natural numbers less than $n \ge 2$. We can write
            $$ f(x_i)_i = f_d(x_1, \cdots, x_{n-1}) \cdot x_n^d + \cdots + f_0(x_1, \cdots, x_{n-1}) $$
            For any $a_1, \cdots, a_{n-1} \in k$, the one-variable polynomial $f(a_1, \cdots, a_{n-1}, x_n)$ vanishes on $k$, i.e., this is a zero polynomial. Therefore, $f_i(a_1, \cdots, a_{n-1}) = 0$ for all $0 \le i \le d$ holds, and by the induction hypothesis, we can conclude that $f_i(x_1, \cdots, x_{n-1}) = 0$ for all $0 \le i \le d$. This implies that $f(x_i)_i = 0$, and this completes the proof.
        \end{proof}

        Note that there is $\alpha$ such that $ \lvert \alpha \rvert_1 = n$ and $c_\alpha \neq 0$. By the lemma, there is $\lambda_i$'s such that the coefficient of $x_0^n$ is non-zero. Let's denote this constant as $c$, then the polynomial $\frac{1}{c} \cdot g(x_\bullet)$ is monic in $x_0$, and has a root $(a_n, y_j- \lambda_j \cdot a_n)_j$. This implies that $a_n$ is integral over $k[y_j - \lambda_j \cdot a_n]_j$, so the extension $k[a_n, y_j]_j/k[y_j- \lambda_j \cdot a_n]_j$ is integral. By the induction hypothesis, there are algebraically independent $y'_{j'}$'s in $k[y_j - \lambda_j \cdot a_n]_j$ such that $k[y_j - \lambda_j \cdot a_n]_j/k[y'_{j'}]_{j'}$ is integral. By the transitivity of integral extensions, we can conclude that $A/k[y'_{j'}]_{j'}$ is integral, because $A/k[a_n, y_j]_j$, $k[a_n, y_j]_j/k[y_j - \lambda_j \cdot a_n]_j$, and $k[y_j - \lambda_j \cdot a_n]_j/k[y'_{j'}]_{j'}$ are integral. This completes the proof.
    \end{proof}
\end{document}