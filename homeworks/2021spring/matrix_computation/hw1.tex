\documentclass{scrartcl}
\usepackage{../../styles/style}

\usepackage{glossaries-extra}
\usepackage{subfig}
\usepackage[numbered,framed]{matlab-prettifier}
\lstset{
  style              = Matlab-editor,
  basicstyle         = \mlttfamily,
  escapechar         = ",
  mlshowsectionrules = true,
}

%\darkmode
% https://jangsookim.github.io/lectures/vscode/vscode_lecture0.html

\title{
    Matrix Computation and Application \\ \Large
    --- MATLAB Project 1 ---
    }
\author{20190262 Jeongwoo Park}
\date{}

\newglossaryentry{matrix algebra over C}
{
  name={$\mathbb{C}^{m \times n}$},
  description={The matrix algebra consist of all $m$ by $n$ complex matrices.},
  category=symbol
}

\newglossaryentry{group of unitary matrices}
{
  name={$U(m)$},
  description={The matrix group consist of all $m$ by $m$ unitary matrices.},
  category=symbol
}

\begin{document}
    \maketitle
    \tableofcontents

    \begin{abstract}
        \emph{Factorization} is one of the most useful technique in mathematics. There are several kind of factorization of matrices, for example, \href{https://en.wikipedia.org/wiki/Diagonalizable_matrix}{\uwave{diagonalization}}, \href{https://en.wikipedia.org/wiki/Singular_value_decomposition}{\uwave{singular value decomposition}}, and \href{https://en.wikipedia.org/wiki/QR_decomposition}{\uwave{QR decomposition}}. In this article, I'll introduce about QR decompositions and algorithms for to do this.
    \end{abstract}

    \printunsrtglossary[title={Terminologies}]

    \section{QR decomposition Reduced QR decomposition}

    Let's begin with the definition of QR decomposition.

    \begin{Definition}[QR decomposition]
        Let $A \in \mathbb{C}^{m \times n}$ be a matrix. If a unitary matrix $Q \in U(m)$ and a upper triangular matrix $R \in \mathbb{C}^{m \times n}$ satisfies the equality $A=QR$, then this form of equation is called a \emph{QR decomposition of a matrix $A$}.
    \end{Definition}

    Sometimes, it is also convenient to consider a variation of the QR decomposition, which is called \emph{reduced QR decomposition}.

    \begin{Definition}[reduced QR decomposition]
        Let $A \in \mathbb{m \times n}$ be a matrix. If a matrix $Q \in \mathbb{C}^{m \times n}$ consist of orthonormal columns and a upper triangular matrix $R \in \mathbb{C}^{n \times n}$ satisfies the equality $A=QR$, then this form of equation if called a \emph{reduced QR decomposition}.
    \end{Definition}

    To distinguish two kind of QR decompositions, sometimes we use call \emph{full QR decomposition} to denote the original QR decomposition. Then, how can we find a (reduced) $QR$ decomposition?

    Before to do that, notice that full QR decomposition and reduced QR decomposition are the same thing for square matrices. Also, if we can calculate QR decomposition for all square matrices, then we can find a QR decomposition of any matrix. For example, if $A \in \mathbb{C}^{m \times n}$ is a matrix and $m \ge n$, then we can consider a square matrix
    $$
    \begin{pmatrix}
        A & 0
    \end{pmatrix}
    \in \mathbb{C}^{m \times m}
    $$
    by adding zero columns. Assume that $Q'R'$ be a QR decomposition of that matrix, then the equality
    $$
    \begin{pmatrix}
        A & 0
    \end{pmatrix}
    =
    Q
    \begin{pmatrix}
        R & R''
    \end{pmatrix}
    $$
    holds where $R \in \mathbb{C}^{m \times n}$ and $R'' \in \mathbb{C}^{m \times (m-n)}$. In this situation, the equality $A = QR$ gives a QR decomposition. For the case $m \le n$, let's write
    $$
    A =
    \begin{pmatrix}
        A' & A''
    \end{pmatrix}
    $$
    where $A' \in \mathbb{C}^{m \times m}$ and $A'' \in \mathbb{C}^{m \times (n-m)}$. If $A' = Q'R'$ is a QR decomposition, then we can obtain a QR decomposition
    $$ A = Q' \cdot 
    \begin{pmatrix}
        R' & Q'^\ast \cdot R''
    \end{pmatrix}
    $$
    Similarly, we can obtain a reduced QR decomposition for any matrix. In conclusion, it is enough to consider the method to find a reduced QR decomposition, because a full QR decomposition can be immediately calculated from the reduced QR decomposition of a suitable matrix. In the next section, I'll introduce some method to calculate a reduced QR decomposition.
    
    \section{Algorithms for reduced QR decomposition}
    
    There are several algorithms to obtain a reduced QR decomposition, like \href{https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process}{\uwave{classical Gram--Schmidt process}}, \href{https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process#Numerical_stability}{\uwave{modified Gram--Schmidt process}}, and \href{https://en.wikipedia.org/wiki/Householder_transformation#Applications}{\uwave{Householder triangularization}}. The built-in QR decomposition function of MATLAB is based on the Householder triangularization. Example MATLAB codes for classical and modified Gram--Schmidt processes are given in the next subsections.

    \subsection{Classical Gram--Schmidt process}

    \begin{lstlisting}
function [Q,R] = cgs(A) % Classical Gram--Schmidt process for columns of a matrix A

[m,n] = size(A);
Q = zeros(m,n);
R = zeros(n,n);
N = 0;

for j = 1 : n
    v = A(:,j);
    
    for i = 1 : j-1
        R(i,j) = dot(Q(:,i), A(:,j));
        v = v - R(i,j) * Q(:,i);
    end
    
    l = norm(v);
    disp(l)
    
    if l > 10^-18 & N < m % This is due to the error arose by the numerical approximation.
        R(j,j) = l;
        Q(:,j) = v/R(j,j);
        N = N + 1;
    end
end

end
    \end{lstlisting}

    \subsection{Modified Gram--Schmidt process}

    \begin{lstlisting}
function [Q,R] = classical(A) % Classical Gram--Schmidt process for columns of a matrix A

[m,n] = size(A); % size of the given matrix A
Q = zeros(m,n);
R = zeros(n,n);
N = 0;

for j = 1 : n
    v = A(:,j);
    
    for i = 1 : j-1
        R(i,j) = dot(Q(:,i), v);
        v = v - R(i,j) * Q(:,i);
    end
    
    l = norm(v);
    disp(l)
    
    if l > 10^-18 & N < m % This is due to the error arose by the numerical approximation.
        R(j,j) = l;
        Q(:,j) = v/R(j,j);
        N = N + 1;
    end
end

end
    \end{lstlisting}

    \section{Numerical stability of the algorithms}

    Theoretically, the three algorithms for QR decomposition don't have any problem. However, if we do the calculation including numerical errors, then we have to consider the numerical stability of each algorithm. It is well-known that the modified Gram--Schmidt process and Householder triangularization are numerically stable, but the classical Gram--Schmidt process does not. Here are some tables showing the errors of each algorithm.

    \begin{figure}[h]
        \centering
            \begin{subfloat}[][$S = \diag\left(2^{-i}\right)_{1 \le i \le 80}$]{\includegraphics[scale = 0.5]{./images/project_1/plot_1.png}}
            \end{subfloat}
            \begin{subfloat}[][$S = \diag\left(i^{-10}\right)_{1 \le i \le 80}$]{\includegraphics[scale = 0.5]{./images/project_1/plot_2.png}}
            \end{subfloat}
            \\
            \begin{subfloat}[][$S = \diag\left(i^{-4} 2^{-i}\right)_{1 \le i \le 80}$]{\includegraphics[scale = 0.5]{./images/project_1/plot_3.png}}
            \end{subfloat}
            \begin{subfloat}[][$S = \diag\left(2^{-i^{0.9}}\right)_{1 \le i \le 80}$]{\includegraphics[scale = 0.5]{./images/project_1/plot_4.png}}
            \end{subfloat}
        \caption{Error plots of the classical Gram--Schmidt process (cgs), modified Gram--Schmidt process (mgs), and Householder triangularization (qs)}
    \end{figure}

    \subsection{Analysis of the result}

    Why the modified Gram--Schmidt process gives better result? Let's estimate the error with acceptable assumptions. We can assume that the numerical error $\varepsilon_{i,j} \doteq \delta_{i,j} - \langle q_i | q_j \rangle$, where the sign $\doteq$ means the numerical approximation of the value. Simple calculation shows that
    $$ \langle q_{j'} | v_j \rangle \doteq \langle q_{j'} | u_j \rangle - \sum_{j=1}^{j-1} \langle q_i | u_j \rangle \cdot \langle q_{j'} | q_i \rangle \doteq \sum_{i=1}^{j-1} \langle q_i | u_j \rangle \cdot \varepsilon_{i, j'} $$
    where the vector $v_j$ is the $j$-th stage of the classical Gram--Schmidt process, i.e., $v_j = u_j - \sum_{i=1}^{j-1} \langle q_i | u_j \rangle \cdot q_i$. If we assume that $\{\varepsilon_{i,j}, q_i\}_{i,j}$ are independent uniform random variables such that the image of $\varepsilon_{i,j}$ is the interval $[-\varepsilon, \varepsilon]$ and the image of $q_i$ is the sphere $S^{n-1}$, then the expectation of the value $\langle q_{j'} | v_j \rangle^2$ can be calculated as
    \begin{align*}
        \mathbb{E}\left( \left( \sum_{i=1}^{j-1} \langle q_i | u_j \rangle \cdot \varepsilon_{i,j'} \right)^2 \right) &= \mathbb{E} \left( \sum_{i=1}^{j-1} \langle q_i | u_j \rangle^2 \varepsilon_{i,j'}^2 \right)\\
        &= \mathbb{E} \left( \sum_{i=1}^{j-1} \langle q_i | \hat{u_j} \rangle^2 \right) \cdot \lVert u_j \rVert^2 \cdot \frac{\varepsilon^2}{3}\\
        &= \frac{j-1}{3n} \cdot \varepsilon^2 \cdot \lVert u_j \rVert^2
    \end{align*}
    where the \emph{hat} denotes the normalization of a vector. For the modified Gram--Schmidt, it is more complicated, but we can show that the expectation is approximately
    $$ \frac{j-j'}{3n} \left( 1-\frac{1}{m} \right)^{j'-1} \cdot \varepsilon^2 \cdot \lVert u_j \rVert^2 $$
    when we treat the value $\varepsilon^2$ as a zero.\footnote{This is reasonable because number terms including $\varepsilon$ is not too large, but $\varepsilon$ is very small.} Hence, the error of the modified Gram--Schmidt process is much smaller that the error of the classical Gram--Schmidt process.

\end{document}